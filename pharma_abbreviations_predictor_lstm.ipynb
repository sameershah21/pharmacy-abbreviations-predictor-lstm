{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "905a7a2e-6592-42ce-a084-5812a7f4a140",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total abbreviations: 256\n",
      "Vocabulary size: 63\n",
      "Maximum abbreviation length: 7\n",
      "Maximum full form length: 56\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"functional_2\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"functional_2\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)        </span>┃<span style=\"font-weight: bold\"> Output Shape      </span>┃<span style=\"font-weight: bold\">    Param # </span>┃<span style=\"font-weight: bold\"> Connected to      </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━┩\n",
       "│ input_layer_4       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">7</span>)         │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                 │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)        │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ input_layer_5       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">55</span>)        │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                 │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)        │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ embedding_4         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">7</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)    │      <span style=\"color: #00af00; text-decoration-color: #00af00\">8,064</span> │ input_layer_4[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]… │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Embedding</span>)         │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ not_equal_4         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">7</span>)         │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ input_layer_4[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]… │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">NotEqual</span>)          │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ embedding_5         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">55</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)   │      <span style=\"color: #00af00; text-decoration-color: #00af00\">8,064</span> │ input_layer_5[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]… │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Embedding</span>)         │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ lstm_4 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)       │ [(<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>),     │    <span style=\"color: #00af00; text-decoration-color: #00af00\">394,240</span> │ embedding_4[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>… │\n",
       "│                     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>),      │            │ not_equal_4[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>] │\n",
       "│                     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)]      │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ lstm_5 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">55</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)   │    <span style=\"color: #00af00; text-decoration-color: #00af00\">394,240</span> │ embedding_5[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>… │\n",
       "│                     │                   │            │ lstm_4[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>],     │\n",
       "│                     │                   │            │ lstm_4[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">2</span>]      │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ not_equal_5         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">55</span>)        │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ input_layer_5[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]… │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">NotEqual</span>)          │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ time_distributed_2  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">55</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">63</span>)    │     <span style=\"color: #00af00; text-decoration-color: #00af00\">16,191</span> │ lstm_5[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>],     │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">TimeDistributed</span>)   │                   │            │ not_equal_5[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>] │\n",
       "└─────────────────────┴───────────────────┴────────────┴───────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)       \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape     \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m   Param #\u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mConnected to     \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━┩\n",
       "│ input_layer_4       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m7\u001b[0m)         │          \u001b[38;5;34m0\u001b[0m │ -                 │\n",
       "│ (\u001b[38;5;33mInputLayer\u001b[0m)        │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ input_layer_5       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m55\u001b[0m)        │          \u001b[38;5;34m0\u001b[0m │ -                 │\n",
       "│ (\u001b[38;5;33mInputLayer\u001b[0m)        │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ embedding_4         │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m7\u001b[0m, \u001b[38;5;34m128\u001b[0m)    │      \u001b[38;5;34m8,064\u001b[0m │ input_layer_4[\u001b[38;5;34m0\u001b[0m]… │\n",
       "│ (\u001b[38;5;33mEmbedding\u001b[0m)         │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ not_equal_4         │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m7\u001b[0m)         │          \u001b[38;5;34m0\u001b[0m │ input_layer_4[\u001b[38;5;34m0\u001b[0m]… │\n",
       "│ (\u001b[38;5;33mNotEqual\u001b[0m)          │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ embedding_5         │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m55\u001b[0m, \u001b[38;5;34m128\u001b[0m)   │      \u001b[38;5;34m8,064\u001b[0m │ input_layer_5[\u001b[38;5;34m0\u001b[0m]… │\n",
       "│ (\u001b[38;5;33mEmbedding\u001b[0m)         │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ lstm_4 (\u001b[38;5;33mLSTM\u001b[0m)       │ [(\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m),     │    \u001b[38;5;34m394,240\u001b[0m │ embedding_4[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m… │\n",
       "│                     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m),      │            │ not_equal_4[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m] │\n",
       "│                     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)]      │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ lstm_5 (\u001b[38;5;33mLSTM\u001b[0m)       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m55\u001b[0m, \u001b[38;5;34m256\u001b[0m)   │    \u001b[38;5;34m394,240\u001b[0m │ embedding_5[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m… │\n",
       "│                     │                   │            │ lstm_4[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m1\u001b[0m],     │\n",
       "│                     │                   │            │ lstm_4[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m2\u001b[0m]      │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ not_equal_5         │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m55\u001b[0m)        │          \u001b[38;5;34m0\u001b[0m │ input_layer_5[\u001b[38;5;34m0\u001b[0m]… │\n",
       "│ (\u001b[38;5;33mNotEqual\u001b[0m)          │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ time_distributed_2  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m55\u001b[0m, \u001b[38;5;34m63\u001b[0m)    │     \u001b[38;5;34m16,191\u001b[0m │ lstm_5[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m],     │\n",
       "│ (\u001b[38;5;33mTimeDistributed\u001b[0m)   │                   │            │ not_equal_5[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m] │\n",
       "└─────────────────────┴───────────────────┴────────────┴───────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">820,799</span> (3.13 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m820,799\u001b[0m (3.13 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">820,799</span> (3.13 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m820,799\u001b[0m (3.13 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 115ms/step - accuracy: 0.0309 - loss: 4.1067 - val_accuracy: 0.0399 - val_loss: 3.6487 - learning_rate: 0.0010\n",
      "Epoch 2/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 68ms/step - accuracy: 0.0399 - loss: 3.4577 - val_accuracy: 0.0444 - val_loss: 3.2002 - learning_rate: 0.0010\n",
      "Epoch 3/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 76ms/step - accuracy: 0.0405 - loss: 3.0868 - val_accuracy: 0.0406 - val_loss: 3.0939 - learning_rate: 0.0010\n",
      "Epoch 4/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 75ms/step - accuracy: 0.0412 - loss: 3.0259 - val_accuracy: 0.0406 - val_loss: 3.0592 - learning_rate: 0.0010\n",
      "Epoch 5/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 81ms/step - accuracy: 0.0408 - loss: 2.9941 - val_accuracy: 0.0406 - val_loss: 3.0476 - learning_rate: 0.0010\n",
      "Epoch 6/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 78ms/step - accuracy: 0.0453 - loss: 2.9698 - val_accuracy: 0.0427 - val_loss: 3.0152 - learning_rate: 0.0010\n",
      "Epoch 7/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 81ms/step - accuracy: 0.0450 - loss: 2.9511 - val_accuracy: 0.0486 - val_loss: 2.9896 - learning_rate: 0.0010\n",
      "Epoch 8/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 81ms/step - accuracy: 0.0557 - loss: 2.9151 - val_accuracy: 0.0587 - val_loss: 2.9442 - learning_rate: 0.0010\n",
      "Epoch 9/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 81ms/step - accuracy: 0.0620 - loss: 2.8645 - val_accuracy: 0.0682 - val_loss: 2.9028 - learning_rate: 0.0010\n",
      "Epoch 10/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 83ms/step - accuracy: 0.0664 - loss: 2.8097 - val_accuracy: 0.0759 - val_loss: 2.8485 - learning_rate: 0.0010\n",
      "Epoch 11/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 82ms/step - accuracy: 0.0751 - loss: 2.7632 - val_accuracy: 0.0766 - val_loss: 2.8134 - learning_rate: 0.0010\n",
      "Epoch 12/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 88ms/step - accuracy: 0.0766 - loss: 2.7117 - val_accuracy: 0.0794 - val_loss: 2.7743 - learning_rate: 0.0010\n",
      "Epoch 13/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 83ms/step - accuracy: 0.0784 - loss: 2.6665 - val_accuracy: 0.0787 - val_loss: 2.7412 - learning_rate: 0.0010\n",
      "Epoch 14/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 92ms/step - accuracy: 0.0805 - loss: 2.6267 - val_accuracy: 0.0815 - val_loss: 2.7218 - learning_rate: 0.0010\n",
      "Epoch 15/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 90ms/step - accuracy: 0.0884 - loss: 2.6066 - val_accuracy: 0.0822 - val_loss: 2.7013 - learning_rate: 0.0010\n",
      "Epoch 16/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 97ms/step - accuracy: 0.0882 - loss: 2.5770 - val_accuracy: 0.0906 - val_loss: 2.6805 - learning_rate: 0.0010\n",
      "Epoch 17/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 96ms/step - accuracy: 0.0935 - loss: 2.5478 - val_accuracy: 0.0874 - val_loss: 2.6661 - learning_rate: 0.0010\n",
      "Epoch 18/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 102ms/step - accuracy: 0.0913 - loss: 2.5402 - val_accuracy: 0.0909 - val_loss: 2.6372 - learning_rate: 0.0010\n",
      "Epoch 19/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 100ms/step - accuracy: 0.0923 - loss: 2.5201 - val_accuracy: 0.0934 - val_loss: 2.6274 - learning_rate: 0.0010\n",
      "Epoch 20/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 104ms/step - accuracy: 0.0955 - loss: 2.5024 - val_accuracy: 0.0951 - val_loss: 2.6029 - learning_rate: 0.0010\n",
      "Epoch 21/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 104ms/step - accuracy: 0.0961 - loss: 2.4656 - val_accuracy: 0.0951 - val_loss: 2.5900 - learning_rate: 0.0010\n",
      "Epoch 22/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 102ms/step - accuracy: 0.0984 - loss: 2.4397 - val_accuracy: 0.1010 - val_loss: 2.5844 - learning_rate: 0.0010\n",
      "Epoch 23/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 113ms/step - accuracy: 0.1045 - loss: 2.4316 - val_accuracy: 0.0962 - val_loss: 2.5647 - learning_rate: 0.0010\n",
      "Epoch 24/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 101ms/step - accuracy: 0.0995 - loss: 2.4338 - val_accuracy: 0.0990 - val_loss: 2.5533 - learning_rate: 0.0010\n",
      "Epoch 25/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 111ms/step - accuracy: 0.1066 - loss: 2.4014 - val_accuracy: 0.1000 - val_loss: 2.5408 - learning_rate: 0.0010\n",
      "Epoch 26/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 117ms/step - accuracy: 0.1088 - loss: 2.3925 - val_accuracy: 0.1003 - val_loss: 2.5359 - learning_rate: 0.0010\n",
      "Epoch 27/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 110ms/step - accuracy: 0.1107 - loss: 2.3640 - val_accuracy: 0.1045 - val_loss: 2.5198 - learning_rate: 0.0010\n",
      "Epoch 28/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 95ms/step - accuracy: 0.1141 - loss: 2.3576 - val_accuracy: 0.1049 - val_loss: 2.5221 - learning_rate: 0.0010\n",
      "Epoch 29/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 107ms/step - accuracy: 0.1135 - loss: 2.3535 - val_accuracy: 0.1087 - val_loss: 2.4983 - learning_rate: 0.0010\n",
      "Epoch 30/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 101ms/step - accuracy: 0.1130 - loss: 2.3166 - val_accuracy: 0.1080 - val_loss: 2.4991 - learning_rate: 0.0010\n",
      "Epoch 31/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 101ms/step - accuracy: 0.1204 - loss: 2.3170 - val_accuracy: 0.1091 - val_loss: 2.4873 - learning_rate: 0.0010\n",
      "Epoch 32/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 117ms/step - accuracy: 0.1146 - loss: 2.3134 - val_accuracy: 0.1105 - val_loss: 2.4816 - learning_rate: 0.0010\n",
      "Epoch 33/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 110ms/step - accuracy: 0.1170 - loss: 2.3009 - val_accuracy: 0.1115 - val_loss: 2.4663 - learning_rate: 0.0010\n",
      "Epoch 34/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 106ms/step - accuracy: 0.1229 - loss: 2.2630 - val_accuracy: 0.1143 - val_loss: 2.4603 - learning_rate: 0.0010\n",
      "Epoch 35/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 95ms/step - accuracy: 0.1176 - loss: 2.2769 - val_accuracy: 0.1091 - val_loss: 2.4558 - learning_rate: 0.0010\n",
      "Epoch 36/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 113ms/step - accuracy: 0.1256 - loss: 2.2321 - val_accuracy: 0.1101 - val_loss: 2.4460 - learning_rate: 0.0010\n",
      "Epoch 37/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 113ms/step - accuracy: 0.1331 - loss: 2.2161 - val_accuracy: 0.1119 - val_loss: 2.4302 - learning_rate: 0.0010\n",
      "Epoch 38/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 119ms/step - accuracy: 0.1338 - loss: 2.1952 - val_accuracy: 0.1080 - val_loss: 2.4315 - learning_rate: 0.0010\n",
      "Epoch 39/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 122ms/step - accuracy: 0.1332 - loss: 2.1789 - val_accuracy: 0.1168 - val_loss: 2.3995 - learning_rate: 0.0010\n",
      "Epoch 40/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 106ms/step - accuracy: 0.1376 - loss: 2.1688 - val_accuracy: 0.1112 - val_loss: 2.4058 - learning_rate: 0.0010\n",
      "Epoch 41/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 109ms/step - accuracy: 0.1391 - loss: 2.1503 - val_accuracy: 0.1087 - val_loss: 2.4085 - learning_rate: 0.0010\n",
      "Epoch 42/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 117ms/step - accuracy: 0.1317 - loss: 2.1248 - val_accuracy: 0.1175 - val_loss: 2.3820 - learning_rate: 0.0010\n",
      "Epoch 43/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 116ms/step - accuracy: 0.1445 - loss: 2.1060 - val_accuracy: 0.1154 - val_loss: 2.3622 - learning_rate: 0.0010\n",
      "Epoch 44/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 114ms/step - accuracy: 0.1470 - loss: 2.0717 - val_accuracy: 0.1164 - val_loss: 2.3658 - learning_rate: 0.0010\n",
      "Epoch 45/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 111ms/step - accuracy: 0.1479 - loss: 2.0551 - val_accuracy: 0.1192 - val_loss: 2.3503 - learning_rate: 0.0010\n",
      "Epoch 46/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 108ms/step - accuracy: 0.1486 - loss: 2.0437 - val_accuracy: 0.1178 - val_loss: 2.3430 - learning_rate: 0.0010\n",
      "Epoch 47/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 114ms/step - accuracy: 0.1610 - loss: 1.9876 - val_accuracy: 0.1227 - val_loss: 2.3221 - learning_rate: 0.0010\n",
      "Epoch 48/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 122ms/step - accuracy: 0.1623 - loss: 1.9873 - val_accuracy: 0.1203 - val_loss: 2.3403 - learning_rate: 0.0010\n",
      "Epoch 49/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 124ms/step - accuracy: 0.1518 - loss: 1.9703 - val_accuracy: 0.1315 - val_loss: 2.3073 - learning_rate: 0.0010\n",
      "Epoch 50/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 110ms/step - accuracy: 0.1575 - loss: 1.9633 - val_accuracy: 0.1276 - val_loss: 2.3098 - learning_rate: 0.0010\n",
      "Epoch 51/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 115ms/step - accuracy: 0.1713 - loss: 1.9198 - val_accuracy: 0.1280 - val_loss: 2.2979 - learning_rate: 0.0010\n",
      "Epoch 52/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 111ms/step - accuracy: 0.1643 - loss: 1.9133 - val_accuracy: 0.1199 - val_loss: 2.3000 - learning_rate: 0.0010\n",
      "Epoch 53/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 117ms/step - accuracy: 0.1772 - loss: 1.8852 - val_accuracy: 0.1294 - val_loss: 2.2878 - learning_rate: 0.0010\n",
      "Epoch 54/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 112ms/step - accuracy: 0.1832 - loss: 1.8393 - val_accuracy: 0.1322 - val_loss: 2.3016 - learning_rate: 0.0010\n",
      "Epoch 55/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 104ms/step - accuracy: 0.1810 - loss: 1.8304 - val_accuracy: 0.1329 - val_loss: 2.2973 - learning_rate: 0.0010\n",
      "Epoch 56/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 103ms/step - accuracy: 0.1803 - loss: 1.8289 - val_accuracy: 0.1290 - val_loss: 2.2825 - learning_rate: 0.0010\n",
      "Epoch 57/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 124ms/step - accuracy: 0.1755 - loss: 1.7901 - val_accuracy: 0.1322 - val_loss: 2.2861 - learning_rate: 0.0010\n",
      "Epoch 58/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 120ms/step - accuracy: 0.1909 - loss: 1.7544 - val_accuracy: 0.1367 - val_loss: 2.2817 - learning_rate: 0.0010\n",
      "Epoch 59/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 115ms/step - accuracy: 0.1901 - loss: 1.7423 - val_accuracy: 0.1367 - val_loss: 2.2927 - learning_rate: 0.0010\n",
      "Epoch 60/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 118ms/step - accuracy: 0.1972 - loss: 1.6837 - val_accuracy: 0.1374 - val_loss: 2.2927 - learning_rate: 0.0010\n",
      "Epoch 61/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 119ms/step - accuracy: 0.1925 - loss: 1.6890 - val_accuracy: 0.1378 - val_loss: 2.2923 - learning_rate: 0.0010\n",
      "Epoch 62/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 115ms/step - accuracy: 0.2061 - loss: 1.6476 - val_accuracy: 0.1406 - val_loss: 2.2868 - learning_rate: 0.0010\n",
      "Epoch 63/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 113ms/step - accuracy: 0.2039 - loss: 1.6354 - val_accuracy: 0.1378 - val_loss: 2.2876 - learning_rate: 0.0010\n",
      "Epoch 64/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 116ms/step - accuracy: 0.2161 - loss: 1.5846 - val_accuracy: 0.1402 - val_loss: 2.3103 - learning_rate: 5.0000e-04\n",
      "Epoch 65/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 115ms/step - accuracy: 0.2189 - loss: 1.5652 - val_accuracy: 0.1374 - val_loss: 2.2958 - learning_rate: 5.0000e-04\n",
      "Epoch 66/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 117ms/step - accuracy: 0.2170 - loss: 1.5640 - val_accuracy: 0.1385 - val_loss: 2.2970 - learning_rate: 5.0000e-04\n",
      "Epoch 67/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 115ms/step - accuracy: 0.2164 - loss: 1.5446 - val_accuracy: 0.1406 - val_loss: 2.3068 - learning_rate: 5.0000e-04\n",
      "Epoch 68/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 121ms/step - accuracy: 0.2289 - loss: 1.5096 - val_accuracy: 0.1399 - val_loss: 2.3110 - learning_rate: 5.0000e-04\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "----- Testing Predictions -----\n",
      "RTF   → Predicted: refill too dor\n",
      "        Actual:    Ready To Fill\n",
      "        Match:     ✗\n",
      "\n",
      "RTPB  → Predicted: real-tion rentrint restrint\n",
      "        Actual:    Real-Time Prescription Benefit\n",
      "        Match:     ✗\n",
      "\n",
      "DAW   → Predicted: diseate dister ant\n",
      "        Actual:    Dispense As Written\n",
      "        Match:     ✗\n",
      "\n",
      "NP    → Predicted: ne troc act\n",
      "        Actual:    New Prescription\n",
      "        Match:     ✗\n",
      "\n",
      "RTBF  → Predicted: reall-tion restrint\n",
      "        Actual:    Real-Time Benefit Format\n",
      "        Match:     ✗\n",
      "\n",
      "MD    → Predicted: medical disease\n",
      "        Actual:    Medical Doctor\n",
      "        Match:     ✗\n",
      "\n",
      "DO    → Predicted: dreat intert\n",
      "        Actual:    Doctor of Osteopathy\n",
      "        Match:     ✗\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Complete Fixed Implementation - No Masking Required\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import LSTM, Dense, Embedding, RepeatVector, TimeDistributed, Input\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau\n",
    "import matplotlib.pyplot as plt\n",
    "import pickle\n",
    "\n",
    "# Load the CSV dataset\n",
    "df = pd.read_csv('pharmacy_abbreviations.csv')\n",
    "print(f\"Total abbreviations: {len(df)}\")\n",
    "\n",
    "# Create input and output pairs\n",
    "abbreviations = df['Abbreviation'].str.lower().values\n",
    "full_forms = df['Full Form'].values\n",
    "\n",
    "# Create character-level mappings with special tokens\n",
    "all_text = ''.join(abbreviations) + ''.join(full_forms)\n",
    "chars = sorted(list(set(all_text)))\n",
    "\n",
    "# Add special tokens\n",
    "char_to_idx = {c: i+3 for i, c in enumerate(chars)}\n",
    "char_to_idx['<PAD>'] = 0  # Padding token\n",
    "char_to_idx['<START>'] = 1  # Start token\n",
    "char_to_idx['<END>'] = 2  # End token\n",
    "idx_to_char = {i: c for c, i in char_to_idx.items()}\n",
    "\n",
    "vocab_size = len(char_to_idx)\n",
    "print(f\"Vocabulary size: {vocab_size}\")\n",
    "\n",
    "# Prepare input sequences (abbreviations)\n",
    "X = [[char_to_idx.get(char.lower(), 0) for char in abbr] for abbr in abbreviations]\n",
    "\n",
    "# Prepare output sequences (full forms) with start and end tokens\n",
    "y_input = [[char_to_idx['<START>']] + [char_to_idx.get(char.lower(), 0) for char in full] for full in full_forms]\n",
    "y_output = [[char_to_idx.get(char.lower(), 0) for char in full] + [char_to_idx['<END>']] for full in full_forms]\n",
    "\n",
    "# Find maximum lengths\n",
    "max_abbr_len = max(len(seq) for seq in X)\n",
    "max_full_len = max(max(len(seq) for seq in y_input), max(len(seq) for seq in y_output))\n",
    "\n",
    "print(f\"Maximum abbreviation length: {max_abbr_len}\")\n",
    "print(f\"Maximum full form length: {max_full_len + 1}\")  # +1 for END token\n",
    "\n",
    "# Pad sequences\n",
    "X_padded = pad_sequences(X, maxlen=max_abbr_len, padding='post')\n",
    "y_input_padded = pad_sequences(y_input, maxlen=max_full_len, padding='post')\n",
    "y_output_padded = pad_sequences(y_output, maxlen=max_full_len, padding='post')\n",
    "\n",
    "# Split into training and validation sets\n",
    "X_train, X_val, y_input_train, y_input_val, y_output_train, y_output_val = train_test_split(\n",
    "    X_padded, y_input_padded, y_output_padded, test_size=0.2, random_state=42\n",
    ")\n",
    "\n",
    "# Reshape y_output_train and y_output_val for sparse_categorical_crossentropy\n",
    "y_output_train = y_output_train.reshape(y_output_train.shape[0], y_output_train.shape[1], 1)\n",
    "y_output_val = y_output_val.reshape(y_output_val.shape[0], y_output_val.shape[1], 1)\n",
    "\n",
    "# Define the model - encoder-decoder model\n",
    "# Encoder\n",
    "encoder_inputs = Input(shape=(max_abbr_len,))\n",
    "encoder_embedding = Embedding(vocab_size, 128, mask_zero=True)(encoder_inputs)\n",
    "encoder_lstm = LSTM(256, return_state=True, dropout=0.2)(encoder_embedding)\n",
    "encoder_outputs, state_h, state_c = encoder_lstm\n",
    "encoder_states = [state_h, state_c]\n",
    "\n",
    "# Decoder\n",
    "decoder_inputs = Input(shape=(max_full_len,))\n",
    "decoder_embedding = Embedding(vocab_size, 128, mask_zero=True)(decoder_inputs)\n",
    "decoder_lstm = LSTM(256, return_sequences=True, dropout=0.2)(decoder_embedding, initial_state=encoder_states)\n",
    "decoder_dense = TimeDistributed(Dense(vocab_size, activation='softmax'))(decoder_lstm)\n",
    "\n",
    "# Define the model\n",
    "model = Model([encoder_inputs, decoder_inputs], decoder_dense)\n",
    "\n",
    "# Compile the model - without any sample_weight_mode\n",
    "model.compile(\n",
    "    optimizer='adam', \n",
    "    loss='sparse_categorical_crossentropy',\n",
    "    metrics=['accuracy']\n",
    ")\n",
    "\n",
    "# Print model summary\n",
    "model.summary()\n",
    "\n",
    "# Define callbacks\n",
    "callbacks = [\n",
    "    EarlyStopping(monitor='val_loss', patience=10, restore_best_weights=True),\n",
    "    ReduceLROnPlateau(monitor='val_loss', factor=0.5, patience=5, min_lr=0.0001)\n",
    "]\n",
    "\n",
    "# Train the model - without sample_weight\n",
    "history = model.fit(\n",
    "    [X_train, y_input_train], y_output_train,\n",
    "    validation_data=([X_val, y_input_val], y_output_val),\n",
    "    epochs=100,\n",
    "    batch_size=32,\n",
    "    callbacks=callbacks\n",
    ")\n",
    "\n",
    "# Save the model\n",
    "model.save('pharmacy_abbreviation_model_fixed.h5')\n",
    "\n",
    "# Save the character mappings\n",
    "with open('char_mappings_fixed.pkl', 'wb') as f:\n",
    "    pickle.dump({'char_to_idx': char_to_idx, 'idx_to_char': idx_to_char}, f)\n",
    "\n",
    "# Save the parameters\n",
    "with open('processed_data_fixed.pkl', 'wb') as f:\n",
    "    pickle.dump({\n",
    "        'max_abbr_len': max_abbr_len,\n",
    "        'max_full_len': max_full_len\n",
    "    }, f)\n",
    "\n",
    "# Plot training history\n",
    "plt.figure(figsize=(12, 5))\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(history.history['loss'])\n",
    "plt.plot(history.history['val_loss'])\n",
    "plt.title('Model Loss')\n",
    "plt.ylabel('Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.legend(['Train', 'Validation'], loc='upper right')\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.plot(history.history['accuracy'])\n",
    "plt.plot(history.history['val_accuracy'])\n",
    "plt.title('Model Accuracy')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.xlabel('Epoch')\n",
    "plt.legend(['Train', 'Validation'], loc='lower right')\n",
    "plt.tight_layout()\n",
    "plt.savefig('training_history_fixed.png')\n",
    "plt.close()\n",
    "\n",
    "# Function to predict full form\n",
    "def predict_full_form(abbreviation, model, char_to_idx, idx_to_char, max_abbr_len, max_full_len):\n",
    "    # Encode and pad the input abbreviation\n",
    "    encoded_abbr = [char_to_idx.get(char.lower(), 0) for char in abbreviation]\n",
    "    padded_abbr = pad_sequences([encoded_abbr], maxlen=max_abbr_len, padding='post')\n",
    "    \n",
    "    # Initialize decoder input with START token\n",
    "    decoder_input = np.zeros((1, max_full_len))\n",
    "    decoder_input[0, 0] = char_to_idx['<START>']\n",
    "    \n",
    "    # Generate output sequence\n",
    "    output_text = []\n",
    "    \n",
    "    for i in range(1, max_full_len):\n",
    "        # Get model prediction\n",
    "        predictions = model.predict([padded_abbr, decoder_input], verbose=0)[0]\n",
    "        sampled_token_index = np.argmax(predictions[i-1])\n",
    "        \n",
    "        # Stop if END token is predicted or we reach max length\n",
    "        if sampled_token_index == char_to_idx['<END>']:\n",
    "            break\n",
    "        \n",
    "        # Add predicted character to output (skip padding)\n",
    "        if sampled_token_index > 0 and sampled_token_index != char_to_idx['<PAD>']:\n",
    "            output_text.append(idx_to_char[sampled_token_index])\n",
    "        \n",
    "        # Update decoder input for next prediction\n",
    "        decoder_input[0, i] = sampled_token_index\n",
    "    \n",
    "    return ''.join(output_text)\n",
    "\n",
    "# Test with some examples\n",
    "print(\"\\n----- Testing Predictions -----\")\n",
    "test_abbreviations = ['RTF', 'RTPB', 'DAW', 'NP', 'RTBF', 'MD', 'DO']\n",
    "for abbr in test_abbreviations:\n",
    "    try:\n",
    "        actual = df[df['Abbreviation'].str.lower() == abbr.lower()]['Full Form'].values[0]\n",
    "        predicted = predict_full_form(abbr, model, char_to_idx, idx_to_char, max_abbr_len, max_full_len)\n",
    "        match = \"✓\" if predicted.lower() == actual.lower() else \"✗\"\n",
    "        \n",
    "        print(f\"{abbr:5} → Predicted: {predicted}\")\n",
    "        print(f\"{' ':5}   Actual:    {actual}\")\n",
    "        print(f\"{' ':5}   Match:     {match}\")\n",
    "        print()\n",
    "    except:\n",
    "        print(f\"Error predicting {abbr}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14288eeb-eead-4f43-95cc-a735729291ca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total abbreviations: 256\n",
      "  Abbreviation                       Full Form      Category  \\\n",
      "0          RTF                   Ready To Fill      Workflow   \n",
      "1         RTPB  Real-Time Prescription Benefit        System   \n",
      "2         RTBF        Real-Time Benefit Format        System   \n",
      "3          DAW             Dispense As Written  Prescription   \n",
      "4           NP                New Prescription      Workflow   \n",
      "\n",
      "                                             Context  \n",
      "0  Used to indicate a prescription that has been ...  \n",
      "1  Electronic system that delivers patient-specif...  \n",
      "2  Format for delivering patient benefits informa...  \n",
      "3  Indicates that the exact pharmaceutical produc...  \n",
      "4  Indicates a new prescription that has been rec...  \n",
      "Applying data augmentation...\n",
      "Data size after augmentation: 768 (was 256)\n",
      "Original: rtf -> Ready To Fill\n",
      "Augmented: rtf -> Ready ToFill\n",
      "\n",
      "Original: rtpb -> Real-Time Prescription Benefit\n",
      "Augmented: rtf -> ready to fill\n",
      "\n",
      "Original: rtbf -> Real-Time Benefit Format\n",
      "Augmented: rtpb -> Real-Time Prescription Benefit\n",
      "\n",
      "Original: daw -> Dispense As Written\n",
      "Augmented: rtpb -> Real-Time Prescription Benefit\n",
      "\n",
      "Original: np -> New Prescription\n",
      "Augmented: rtbf -> Real-Time-Benefit Format\n",
      "\n",
      "Vocabulary size: 66\n",
      "Maximum abbreviation length: 7\n",
      "Maximum full form length: 55\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"functional_3\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"functional_3\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)        </span>┃<span style=\"font-weight: bold\"> Output Shape      </span>┃<span style=\"font-weight: bold\">    Param # </span>┃<span style=\"font-weight: bold\"> Connected to      </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━┩\n",
       "│ input_layer_6       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">7</span>)         │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                 │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)        │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ embedding_6         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">7</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)    │     <span style=\"color: #00af00; text-decoration-color: #00af00\">16,896</span> │ input_layer_6[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]… │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Embedding</span>)         │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ input_layer_7       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">55</span>)        │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                 │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)        │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dropout (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">7</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)    │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ embedding_6[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>] │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ not_equal_6         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">7</span>)         │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ input_layer_6[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]… │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">NotEqual</span>)          │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ embedding_7         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">55</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)   │     <span style=\"color: #00af00; text-decoration-color: #00af00\">16,896</span> │ input_layer_7[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]… │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Embedding</span>)         │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ bidirectional_2     │ [(<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">7</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1024</span>), │  <span style=\"color: #00af00; text-decoration-color: #00af00\">3,149,824</span> │ dropout[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>],    │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Bidirectional</span>)     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>),      │            │ not_equal_6[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>] │\n",
       "│                     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>),      │            │                   │\n",
       "│                     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>),      │            │                   │\n",
       "│                     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)]      │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dropout_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>) │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">55</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)   │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ embedding_7[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>] │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ concatenate_4       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1024</span>)      │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ bidirectional_2[<span style=\"color: #00af00; text-decoration-color: #00af00\">…</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Concatenate</span>)       │                   │            │ bidirectional_2[<span style=\"color: #00af00; text-decoration-color: #00af00\">…</span> │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ concatenate_5       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1024</span>)      │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ bidirectional_2[<span style=\"color: #00af00; text-decoration-color: #00af00\">…</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Concatenate</span>)       │                   │            │ bidirectional_2[<span style=\"color: #00af00; text-decoration-color: #00af00\">…</span> │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ lstm_7 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">55</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1024</span>)  │  <span style=\"color: #00af00; text-decoration-color: #00af00\">5,246,976</span> │ dropout_1[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>],  │\n",
       "│                     │                   │            │ concatenate_4[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]… │\n",
       "│                     │                   │            │ concatenate_5[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]… │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dropout_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>) │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">55</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1024</span>)  │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ lstm_7[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]      │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dense_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">55</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">66</span>)    │     <span style=\"color: #00af00; text-decoration-color: #00af00\">67,650</span> │ dropout_2[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   │\n",
       "└─────────────────────┴───────────────────┴────────────┴───────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)       \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape     \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m   Param #\u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mConnected to     \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━┩\n",
       "│ input_layer_6       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m7\u001b[0m)         │          \u001b[38;5;34m0\u001b[0m │ -                 │\n",
       "│ (\u001b[38;5;33mInputLayer\u001b[0m)        │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ embedding_6         │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m7\u001b[0m, \u001b[38;5;34m256\u001b[0m)    │     \u001b[38;5;34m16,896\u001b[0m │ input_layer_6[\u001b[38;5;34m0\u001b[0m]… │\n",
       "│ (\u001b[38;5;33mEmbedding\u001b[0m)         │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ input_layer_7       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m55\u001b[0m)        │          \u001b[38;5;34m0\u001b[0m │ -                 │\n",
       "│ (\u001b[38;5;33mInputLayer\u001b[0m)        │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dropout (\u001b[38;5;33mDropout\u001b[0m)   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m7\u001b[0m, \u001b[38;5;34m256\u001b[0m)    │          \u001b[38;5;34m0\u001b[0m │ embedding_6[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m] │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ not_equal_6         │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m7\u001b[0m)         │          \u001b[38;5;34m0\u001b[0m │ input_layer_6[\u001b[38;5;34m0\u001b[0m]… │\n",
       "│ (\u001b[38;5;33mNotEqual\u001b[0m)          │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ embedding_7         │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m55\u001b[0m, \u001b[38;5;34m256\u001b[0m)   │     \u001b[38;5;34m16,896\u001b[0m │ input_layer_7[\u001b[38;5;34m0\u001b[0m]… │\n",
       "│ (\u001b[38;5;33mEmbedding\u001b[0m)         │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ bidirectional_2     │ [(\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m7\u001b[0m, \u001b[38;5;34m1024\u001b[0m), │  \u001b[38;5;34m3,149,824\u001b[0m │ dropout[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m],    │\n",
       "│ (\u001b[38;5;33mBidirectional\u001b[0m)     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m512\u001b[0m),      │            │ not_equal_6[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m] │\n",
       "│                     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m512\u001b[0m),      │            │                   │\n",
       "│                     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m512\u001b[0m),      │            │                   │\n",
       "│                     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m512\u001b[0m)]      │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dropout_1 (\u001b[38;5;33mDropout\u001b[0m) │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m55\u001b[0m, \u001b[38;5;34m256\u001b[0m)   │          \u001b[38;5;34m0\u001b[0m │ embedding_7[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m] │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ concatenate_4       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1024\u001b[0m)      │          \u001b[38;5;34m0\u001b[0m │ bidirectional_2[\u001b[38;5;34m…\u001b[0m │\n",
       "│ (\u001b[38;5;33mConcatenate\u001b[0m)       │                   │            │ bidirectional_2[\u001b[38;5;34m…\u001b[0m │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ concatenate_5       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1024\u001b[0m)      │          \u001b[38;5;34m0\u001b[0m │ bidirectional_2[\u001b[38;5;34m…\u001b[0m │\n",
       "│ (\u001b[38;5;33mConcatenate\u001b[0m)       │                   │            │ bidirectional_2[\u001b[38;5;34m…\u001b[0m │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ lstm_7 (\u001b[38;5;33mLSTM\u001b[0m)       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m55\u001b[0m, \u001b[38;5;34m1024\u001b[0m)  │  \u001b[38;5;34m5,246,976\u001b[0m │ dropout_1[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m],  │\n",
       "│                     │                   │            │ concatenate_4[\u001b[38;5;34m0\u001b[0m]… │\n",
       "│                     │                   │            │ concatenate_5[\u001b[38;5;34m0\u001b[0m]… │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dropout_2 (\u001b[38;5;33mDropout\u001b[0m) │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m55\u001b[0m, \u001b[38;5;34m1024\u001b[0m)  │          \u001b[38;5;34m0\u001b[0m │ lstm_7[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]      │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dense_3 (\u001b[38;5;33mDense\u001b[0m)     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m55\u001b[0m, \u001b[38;5;34m66\u001b[0m)    │     \u001b[38;5;34m67,650\u001b[0m │ dropout_2[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   │\n",
       "└─────────────────────┴───────────────────┴────────────┴───────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">8,498,242</span> (32.42 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m8,498,242\u001b[0m (32.42 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">8,498,242</span> (32.42 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m8,498,242\u001b[0m (32.42 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 401ms/step - accuracy: 0.0393 - loss: 3.6342"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 441ms/step - accuracy: 0.0393 - loss: 3.6261 - val_accuracy: 0.0298 - val_loss: 3.0269 - learning_rate: 5.0000e-04\n",
      "Epoch 2/200\n",
      "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 413ms/step - accuracy: 0.0431 - loss: 3.0083"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 446ms/step - accuracy: 0.0433 - loss: 3.0074 - val_accuracy: 0.0638 - val_loss: 2.8804 - learning_rate: 5.0000e-04\n",
      "Epoch 3/200\n",
      "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 440ms/step - accuracy: 0.0651 - loss: 2.8373"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 478ms/step - accuracy: 0.0652 - loss: 2.8361 - val_accuracy: 0.0795 - val_loss: 2.7022 - learning_rate: 5.0000e-04\n",
      "Epoch 4/200\n",
      "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 495ms/step - accuracy: 0.0803 - loss: 2.6893"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 532ms/step - accuracy: 0.0804 - loss: 2.6885 - val_accuracy: 0.0914 - val_loss: 2.5973 - learning_rate: 5.0000e-04\n",
      "Epoch 5/200\n",
      "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 489ms/step - accuracy: 0.0917 - loss: 2.5835"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 525ms/step - accuracy: 0.0918 - loss: 2.5827 - val_accuracy: 0.1018 - val_loss: 2.5180 - learning_rate: 5.0000e-04\n",
      "Epoch 6/200\n",
      "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 493ms/step - accuracy: 0.1000 - loss: 2.5034"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 532ms/step - accuracy: 0.1001 - loss: 2.5026 - val_accuracy: 0.1061 - val_loss: 2.4454 - learning_rate: 5.0000e-04\n",
      "Epoch 7/200\n",
      "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 488ms/step - accuracy: 0.1085 - loss: 2.4184"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 524ms/step - accuracy: 0.1086 - loss: 2.4176 - val_accuracy: 0.1149 - val_loss: 2.3748 - learning_rate: 5.0000e-04\n",
      "Epoch 8/200\n",
      "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 497ms/step - accuracy: 0.1173 - loss: 2.3349"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 533ms/step - accuracy: 0.1175 - loss: 2.3340 - val_accuracy: 0.1233 - val_loss: 2.2972 - learning_rate: 5.0000e-04\n",
      "Epoch 9/200\n",
      "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 499ms/step - accuracy: 0.1300 - loss: 2.2379"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 537ms/step - accuracy: 0.1301 - loss: 2.2369 - val_accuracy: 0.1344 - val_loss: 2.2044 - learning_rate: 5.0000e-04\n",
      "Epoch 10/200\n",
      "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 494ms/step - accuracy: 0.1450 - loss: 2.1285"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 531ms/step - accuracy: 0.1452 - loss: 2.1274 - val_accuracy: 0.1458 - val_loss: 2.1090 - learning_rate: 5.0000e-04\n",
      "Epoch 11/200\n",
      "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 501ms/step - accuracy: 0.1575 - loss: 2.0079"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 537ms/step - accuracy: 0.1577 - loss: 2.0067 - val_accuracy: 0.1581 - val_loss: 1.9930 - learning_rate: 5.0000e-04\n",
      "Epoch 12/200\n",
      "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 497ms/step - accuracy: 0.1763 - loss: 1.8591"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 534ms/step - accuracy: 0.1765 - loss: 1.8579 - val_accuracy: 0.1751 - val_loss: 1.8728 - learning_rate: 5.0000e-04\n",
      "Epoch 13/200\n",
      "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 500ms/step - accuracy: 0.1969 - loss: 1.7020"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 539ms/step - accuracy: 0.1972 - loss: 1.7006 - val_accuracy: 0.1948 - val_loss: 1.7360 - learning_rate: 5.0000e-04\n",
      "Epoch 14/200\n",
      "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 500ms/step - accuracy: 0.2179 - loss: 1.5219"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 539ms/step - accuracy: 0.2181 - loss: 1.5206 - val_accuracy: 0.2138 - val_loss: 1.5893 - learning_rate: 5.0000e-04\n",
      "Epoch 15/200\n",
      "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 497ms/step - accuracy: 0.2392 - loss: 1.3587"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 537ms/step - accuracy: 0.2395 - loss: 1.3573 - val_accuracy: 0.2333 - val_loss: 1.4270 - learning_rate: 5.0000e-04\n",
      "Epoch 16/200\n",
      "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 492ms/step - accuracy: 0.2592 - loss: 1.1662"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 528ms/step - accuracy: 0.2595 - loss: 1.1654 - val_accuracy: 0.2490 - val_loss: 1.2866 - learning_rate: 5.0000e-04\n",
      "Epoch 17/200\n",
      "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 496ms/step - accuracy: 0.2864 - loss: 0.9916"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 537ms/step - accuracy: 0.2867 - loss: 0.9906 - val_accuracy: 0.2660 - val_loss: 1.1602 - learning_rate: 5.0000e-04\n",
      "Epoch 18/200\n",
      "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 500ms/step - accuracy: 0.3071 - loss: 0.8312"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 539ms/step - accuracy: 0.3073 - loss: 0.8306 - val_accuracy: 0.2818 - val_loss: 1.0192 - learning_rate: 5.0000e-04\n",
      "Epoch 19/200\n",
      "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 491ms/step - accuracy: 0.3243 - loss: 0.6998"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 531ms/step - accuracy: 0.3245 - loss: 0.6991 - val_accuracy: 0.2982 - val_loss: 0.9173 - learning_rate: 5.0000e-04\n",
      "Epoch 20/200\n",
      "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 497ms/step - accuracy: 0.3392 - loss: 0.5888"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 536ms/step - accuracy: 0.3394 - loss: 0.5883 - val_accuracy: 0.3119 - val_loss: 0.8079 - learning_rate: 5.0000e-04\n",
      "Epoch 21/200\n",
      "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 506ms/step - accuracy: 0.3480 - loss: 0.4915"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 544ms/step - accuracy: 0.3482 - loss: 0.4911 - val_accuracy: 0.3244 - val_loss: 0.7232 - learning_rate: 5.0000e-04\n",
      "Epoch 22/200\n",
      "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 503ms/step - accuracy: 0.3581 - loss: 0.4108"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 542ms/step - accuracy: 0.3584 - loss: 0.4104 - val_accuracy: 0.3306 - val_loss: 0.6508 - learning_rate: 5.0000e-04\n",
      "Epoch 23/200\n",
      "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 500ms/step - accuracy: 0.3653 - loss: 0.3458"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 540ms/step - accuracy: 0.3655 - loss: 0.3456 - val_accuracy: 0.3361 - val_loss: 0.5921 - learning_rate: 5.0000e-04\n",
      "Epoch 24/200\n",
      "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 516ms/step - accuracy: 0.3708 - loss: 0.2958"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 555ms/step - accuracy: 0.3710 - loss: 0.2956 - val_accuracy: 0.3414 - val_loss: 0.5508 - learning_rate: 5.0000e-04\n",
      "Epoch 25/200\n",
      "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 509ms/step - accuracy: 0.3759 - loss: 0.2452"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 548ms/step - accuracy: 0.3761 - loss: 0.2452 - val_accuracy: 0.3446 - val_loss: 0.5297 - learning_rate: 5.0000e-04\n",
      "Epoch 26/200\n",
      "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 506ms/step - accuracy: 0.3771 - loss: 0.2254"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 545ms/step - accuracy: 0.3773 - loss: 0.2253 - val_accuracy: 0.3443 - val_loss: 0.5263 - learning_rate: 5.0000e-04\n",
      "Epoch 27/200\n",
      "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 511ms/step - accuracy: 0.3786 - loss: 0.2018"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 551ms/step - accuracy: 0.3788 - loss: 0.2017 - val_accuracy: 0.3470 - val_loss: 0.4880 - learning_rate: 5.0000e-04\n",
      "Epoch 28/200\n",
      "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 519ms/step - accuracy: 0.3805 - loss: 0.1810"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 559ms/step - accuracy: 0.3807 - loss: 0.1809 - val_accuracy: 0.3468 - val_loss: 0.4858 - learning_rate: 5.0000e-04\n",
      "Epoch 29/200\n",
      "\u001b[1m 3/39\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m18s\u001b[0m 506ms/step - accuracy: 0.3681 - loss: 0.1539"
     ]
    }
   ],
   "source": [
    "#version 2\n",
    "# Enhanced Pharmacy Abbreviation Predictor - Complete Implementation\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Model, load_model\n",
    "from tensorflow.keras.layers import LSTM, Dense, Embedding, Bidirectional, Input, Dropout, concatenate\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau, ModelCheckpoint\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "import matplotlib.pyplot as plt\n",
    "import pickle\n",
    "import os\n",
    "import random\n",
    "import string\n",
    "\n",
    "# Set random seeds for reproducibility\n",
    "np.random.seed(42)\n",
    "tf.random.set_seed(42)\n",
    "random.seed(42)\n",
    "\n",
    "# Load the CSV dataset\n",
    "df = pd.read_csv('pharmacy_abbreviations.csv')\n",
    "print(f\"Total abbreviations: {len(df)}\")\n",
    "print(df.head())\n",
    "\n",
    "# Create input and output pairs\n",
    "abbreviations = df['Abbreviation'].str.lower().values\n",
    "full_forms = df['Full Form'].values\n",
    "\n",
    "# Data augmentation function\n",
    "def augment_data(abbreviations, full_forms, augment_factor=2):\n",
    "    \"\"\"Create augmented versions of the data by:\n",
    "    1. Changing case (uppercase/lowercase/title case)\n",
    "    2. Adding slight misspellings\n",
    "    3. Adding small variations\n",
    "    \"\"\"\n",
    "    aug_abbreviations = list(abbreviations)\n",
    "    aug_full_forms = list(full_forms)\n",
    "    \n",
    "    for i in range(len(abbreviations)):\n",
    "        abbr = abbreviations[i]\n",
    "        full = full_forms[i]\n",
    "        \n",
    "        for _ in range(augment_factor - 1):  # -1 because we already have the original\n",
    "            # Decide on augmentation type\n",
    "            aug_type = random.choice(['case', 'misspell', 'variation'])\n",
    "            \n",
    "            if aug_type == 'case':\n",
    "                # Change case of full form\n",
    "                case_type = random.choice(['lower', 'upper', 'title'])\n",
    "                if case_type == 'lower':\n",
    "                    aug_full = full.lower()\n",
    "                elif case_type == 'upper':\n",
    "                    aug_full = full.upper()\n",
    "                else:\n",
    "                    aug_full = full.title()\n",
    "                aug_abbr = abbr\n",
    "                \n",
    "            elif aug_type == 'misspell':\n",
    "                # Add a minor misspelling to full form (1 character change)\n",
    "                if len(full) > 3:  # Only if long enough\n",
    "                    pos = random.randint(0, len(full)-1)\n",
    "                    chars = list(full)\n",
    "                    \n",
    "                    # Decide what type of misspelling\n",
    "                    misspell_type = random.choice(['swap', 'substitute', 'insert', 'delete'])\n",
    "                    \n",
    "                    if misspell_type == 'swap' and pos < len(full) - 1:\n",
    "                        # Swap two adjacent characters\n",
    "                        chars[pos], chars[pos+1] = chars[pos+1], chars[pos]\n",
    "                    elif misspell_type == 'substitute':\n",
    "                        # Substitute a character\n",
    "                        chars[pos] = random.choice(string.ascii_letters + ' -')\n",
    "                    elif misspell_type == 'insert' and len(full) < 50:\n",
    "                        # Insert a character\n",
    "                        chars.insert(pos, random.choice(string.ascii_letters + ' -'))\n",
    "                    elif misspell_type == 'delete' and len(full) > 2:\n",
    "                        # Delete a character\n",
    "                        chars.pop(pos)\n",
    "                    \n",
    "                    aug_full = ''.join(chars)\n",
    "                else:\n",
    "                    aug_full = full\n",
    "                    \n",
    "                aug_abbr = abbr\n",
    "                \n",
    "            else:  # variation\n",
    "                # Create a variation by adding/removing spaces or changing separators\n",
    "                if ' ' in full:\n",
    "                    if random.random() < 0.5:\n",
    "                        # Remove a space\n",
    "                        parts = full.split(' ')\n",
    "                        if len(parts) > 1:\n",
    "                            join_idx = random.randint(0, len(parts)-2)\n",
    "                            parts[join_idx] = parts[join_idx] + parts[join_idx+1]\n",
    "                            parts.pop(join_idx+1)\n",
    "                        aug_full = ' '.join(parts)\n",
    "                    else:\n",
    "                        # Change a separator\n",
    "                        sep = random.choice(['-', '/', '&'])\n",
    "                        aug_full = full.replace(' ', sep, 1)\n",
    "                elif '-' in full:\n",
    "                    # Change hyphen to space or another separator\n",
    "                    sep = random.choice([' ', '/', '&'])\n",
    "                    aug_full = full.replace('-', sep, 1)\n",
    "                else:\n",
    "                    # No easy variation, just use original\n",
    "                    aug_full = full\n",
    "                \n",
    "                aug_abbr = abbr\n",
    "            \n",
    "            # Add augmented pair\n",
    "            aug_abbreviations.append(aug_abbr)\n",
    "            aug_full_forms.append(aug_full)\n",
    "    \n",
    "    return np.array(aug_abbreviations), np.array(aug_full_forms)\n",
    "\n",
    "# Apply data augmentation\n",
    "print(\"Applying data augmentation...\")\n",
    "aug_abbreviations, aug_full_forms = augment_data(abbreviations, full_forms, augment_factor=3)\n",
    "print(f\"Data size after augmentation: {len(aug_abbreviations)} (was {len(abbreviations)})\")\n",
    "\n",
    "# Display some augmented examples\n",
    "for i in range(5):\n",
    "    orig_idx = i\n",
    "    aug_idx = len(abbreviations) + i\n",
    "    print(f\"Original: {abbreviations[orig_idx]} -> {full_forms[orig_idx]}\")\n",
    "    print(f\"Augmented: {aug_abbreviations[aug_idx]} -> {aug_full_forms[aug_idx]}\")\n",
    "    print()\n",
    "\n",
    "# Create character-level mappings with special tokens\n",
    "all_text = ''.join(aug_abbreviations) + ''.join(aug_full_forms)\n",
    "chars = sorted(list(set(all_text)))\n",
    "\n",
    "# Add special tokens\n",
    "char_to_idx = {c: i+3 for i, c in enumerate(chars)}\n",
    "char_to_idx['<PAD>'] = 0  # Padding token\n",
    "char_to_idx['<START>'] = 1  # Start token\n",
    "char_to_idx['<END>'] = 2  # End token\n",
    "idx_to_char = {i: c for c, i in char_to_idx.items()}\n",
    "\n",
    "vocab_size = len(char_to_idx)\n",
    "print(f\"Vocabulary size: {vocab_size}\")\n",
    "\n",
    "# Prepare input sequences (abbreviations)\n",
    "X = [[char_to_idx.get(char.lower(), 0) for char in abbr] for abbr in aug_abbreviations]\n",
    "\n",
    "# Prepare output sequences (full forms) with start and end tokens\n",
    "y_input = [[char_to_idx['<START>']] + [char_to_idx.get(char.lower(), 0) for char in full] for full in aug_full_forms]\n",
    "y_output = [[char_to_idx.get(char.lower(), 0) for char in full] + [char_to_idx['<END>']] for full in aug_full_forms]\n",
    "\n",
    "# Find maximum lengths\n",
    "max_abbr_len = max(len(seq) for seq in X)\n",
    "max_full_len = max(max(len(seq) for seq in y_input), max(len(seq) for seq in y_output))\n",
    "\n",
    "print(f\"Maximum abbreviation length: {max_abbr_len}\")\n",
    "print(f\"Maximum full form length: {max_full_len}\")\n",
    "\n",
    "# Pad sequences\n",
    "X_padded = pad_sequences(X, maxlen=max_abbr_len, padding='post')\n",
    "y_input_padded = pad_sequences(y_input, maxlen=max_full_len, padding='post')\n",
    "y_output_padded = pad_sequences(y_output, maxlen=max_full_len, padding='post')\n",
    "\n",
    "# Split into training and validation sets\n",
    "X_train, X_val, y_input_train, y_input_val, y_output_train, y_output_val = train_test_split(\n",
    "    X_padded, y_input_padded, y_output_padded, test_size=0.2, random_state=42\n",
    ")\n",
    "\n",
    "# Reshape y_output for sparse_categorical_crossentropy\n",
    "y_output_train = y_output_train.reshape(y_output_train.shape[0], y_output_train.shape[1], 1)\n",
    "y_output_val = y_output_val.reshape(y_output_val.shape[0], y_output_val.shape[1], 1)\n",
    "\n",
    "# Enhanced model with bidirectional encoder and increased capacity\n",
    "def create_enhanced_model(vocab_size, max_abbr_len, max_full_len):\n",
    "    # Encoder\n",
    "    encoder_inputs = Input(shape=(max_abbr_len,))\n",
    "    encoder_embedding = Embedding(vocab_size, 256, mask_zero=True)(encoder_inputs)\n",
    "    encoder_dropout1 = Dropout(0.2)(encoder_embedding)\n",
    "    \n",
    "    # Bidirectional LSTM for the encoder\n",
    "    encoder_bilstm = Bidirectional(LSTM(512, return_sequences=True, return_state=True, dropout=0.2, recurrent_dropout=0.2))(encoder_dropout1)\n",
    "    \n",
    "    # Bidirectional LSTM returns sequences and states: [output_sequences, forward_h, forward_c, backward_h, backward_c]\n",
    "    encoder_outputs = encoder_bilstm[0]\n",
    "    \n",
    "    # Combine forward and backward states\n",
    "    state_h = concatenate([encoder_bilstm[1], encoder_bilstm[3]])\n",
    "    state_c = concatenate([encoder_bilstm[2], encoder_bilstm[4]])\n",
    "    encoder_states = [state_h, state_c]\n",
    "    \n",
    "    # Decoder\n",
    "    decoder_inputs = Input(shape=(max_full_len,))\n",
    "    decoder_embedding = Embedding(vocab_size, 256, mask_zero=True)(decoder_inputs)\n",
    "    decoder_dropout1 = Dropout(0.2)(decoder_embedding)\n",
    "    \n",
    "    # Decoder LSTM - with doubled units to match concatenated bidirectional encoder states\n",
    "    decoder_lstm = LSTM(1024, return_sequences=True, dropout=0.2, recurrent_dropout=0.2)(decoder_dropout1, initial_state=encoder_states)\n",
    "    decoder_dropout2 = Dropout(0.2)(decoder_lstm)\n",
    "    \n",
    "    # Output layer\n",
    "    decoder_dense = Dense(vocab_size, activation='softmax')(decoder_dropout2)\n",
    "    \n",
    "    # Create model\n",
    "    model = Model([encoder_inputs, decoder_inputs], decoder_dense)\n",
    "    \n",
    "    # Compile with a slightly lower learning rate for stability\n",
    "    optimizer = Adam(learning_rate=0.0005)\n",
    "    model.compile(\n",
    "        optimizer=optimizer,\n",
    "        loss='sparse_categorical_crossentropy',\n",
    "        metrics=['accuracy']\n",
    "    )\n",
    "    \n",
    "    return model\n",
    "\n",
    "# Create the enhanced model\n",
    "model = create_enhanced_model(vocab_size, max_abbr_len, max_full_len)\n",
    "\n",
    "# Print model summary\n",
    "model.summary()\n",
    "\n",
    "# Define enhanced callbacks\n",
    "model_path = 'best_pharmacy_model_enhanced.h5'\n",
    "callbacks = [\n",
    "    ModelCheckpoint(model_path, save_best_only=True, monitor='val_loss'),\n",
    "    EarlyStopping(monitor='val_loss', patience=20, restore_best_weights=True),\n",
    "    ReduceLROnPlateau(monitor='val_loss', factor=0.5, patience=5, min_lr=0.00001, verbose=1)\n",
    "]\n",
    "\n",
    "# Train the model with more epochs\n",
    "history = model.fit(\n",
    "    [X_train, y_input_train], y_output_train,\n",
    "    validation_data=([X_val, y_input_val], y_output_val),\n",
    "    epochs=200,  # Increased epochs\n",
    "    batch_size=16,  # Smaller batch size\n",
    "    callbacks=callbacks,\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "# Save the final model if not already saved by callbacks\n",
    "if not os.path.exists(model_path):\n",
    "    model.save(model_path)\n",
    "\n",
    "# Save the character mappings and parameters\n",
    "with open('char_mappings_enhanced.pkl', 'wb') as f:\n",
    "    pickle.dump({'char_to_idx': char_to_idx, 'idx_to_char': idx_to_char}, f)\n",
    "\n",
    "with open('processed_data_enhanced.pkl', 'wb') as f:\n",
    "    pickle.dump({\n",
    "        'max_abbr_len': max_abbr_len,\n",
    "        'max_full_len': max_full_len\n",
    "    }, f)\n",
    "\n",
    "# Plot training history\n",
    "plt.figure(figsize=(12, 5))\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(history.history['loss'])\n",
    "plt.plot(history.history['val_loss'])\n",
    "plt.title('Model Loss')\n",
    "plt.ylabel('Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.legend(['Train', 'Validation'], loc='upper right')\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.plot(history.history['accuracy'])\n",
    "plt.plot(history.history['val_accuracy'])\n",
    "plt.title('Model Accuracy')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.xlabel('Epoch')\n",
    "plt.legend(['Train', 'Validation'], loc='lower right')\n",
    "plt.tight_layout()\n",
    "plt.savefig('training_history_enhanced.png')\n",
    "plt.close()\n",
    "\n",
    "# Beam search implementation for improved prediction\n",
    "def predict_with_beam_search(model, abbreviation, char_to_idx, idx_to_char, max_abbr_len, max_full_len, beam_width=3):\n",
    "    \"\"\"Predict using beam search to consider multiple character possibilities.\"\"\"\n",
    "    # Encode and pad the input abbreviation\n",
    "    encoded_abbr = [char_to_idx.get(char.lower(), 0) for char in abbreviation]\n",
    "    padded_abbr = pad_sequences([encoded_abbr], maxlen=max_abbr_len, padding='post')\n",
    "    \n",
    "    # Initialize with START token\n",
    "    initial_state = np.zeros((1, max_full_len))\n",
    "    initial_state[0, 0] = char_to_idx['<START>']\n",
    "    \n",
    "    # Initialize beam with (sequence, score, state)\n",
    "    # sequence is a list of character indices\n",
    "    # score is the log probability of the sequence\n",
    "    # state is the decoder input state\n",
    "    beams = [([], 0.0, initial_state)]\n",
    "    \n",
    "    # Generate sequence\n",
    "    for i in range(1, max_full_len):\n",
    "        all_candidates = []\n",
    "        \n",
    "        # Expand each beam\n",
    "        for seq, score, decoder_input in beams:\n",
    "            # Skip if sequence already ended\n",
    "            if seq and seq[-1] == char_to_idx['<END>']:\n",
    "                all_candidates.append((seq, score, decoder_input))\n",
    "                continue\n",
    "                \n",
    "            # Get predictions\n",
    "            predictions = model.predict([padded_abbr, decoder_input], verbose=0)[0]\n",
    "            next_char_probs = predictions[i-1]\n",
    "            \n",
    "            # Get top beam_width probabilities and indices\n",
    "            top_indices = np.argsort(next_char_probs)[-beam_width:]\n",
    "            \n",
    "            # Create new candidates\n",
    "            for idx in top_indices:\n",
    "                # Skip PAD token\n",
    "                if idx == char_to_idx['<PAD>']:\n",
    "                    continue\n",
    "                    \n",
    "                # Create new sequence, score, and state\n",
    "                new_seq = seq + [idx]\n",
    "                # Use log probabilities to prevent underflow\n",
    "                new_score = score + np.log(next_char_probs[idx] + 1e-10)  # Add small epsilon to prevent log(0)\n",
    "                \n",
    "                # Create new decoder input\n",
    "                new_decoder_input = decoder_input.copy()\n",
    "                new_decoder_input[0, i] = idx\n",
    "                \n",
    "                all_candidates.append((new_seq, new_score, new_decoder_input))\n",
    "        \n",
    "        # Keep only the top beam_width candidates\n",
    "        # Sort by score (higher is better)\n",
    "        all_candidates.sort(key=lambda x: x[1], reverse=True)\n",
    "        beams = all_candidates[:beam_width]\n",
    "        \n",
    "        # Check if all beams have ended\n",
    "        if all(beam[0] and beam[0][-1] == char_to_idx['<END>'] for beam in beams):\n",
    "            break\n",
    "    \n",
    "    # Get best sequence\n",
    "    best_seq, best_score, _ = beams[0]\n",
    "    \n",
    "    # Convert to string, removing END token if present\n",
    "    if best_seq and best_seq[-1] == char_to_idx['<END>']:\n",
    "        best_seq = best_seq[:-1]\n",
    "        \n",
    "    result = ''.join(idx_to_char[idx] for idx in best_seq if idx > 0 and idx != char_to_idx['<PAD>'])\n",
    "    return result\n",
    "\n",
    "# Load the best model (which might have been saved by callbacks)\n",
    "best_model = load_model(model_path)\n",
    "\n",
    "# Test with different prediction methods\n",
    "print(\"\\n----- Testing Predictions -----\")\n",
    "test_abbreviations = ['RTF', 'RTPB', 'DAW', 'NP', 'RTBF', 'MD', 'DO']\n",
    "\n",
    "# Function for regular prediction (greedy search)\n",
    "def predict_greedy(abbreviation, model, char_to_idx, idx_to_char, max_abbr_len, max_full_len):\n",
    "    # Encode and pad the input abbreviation\n",
    "    encoded_abbr = [char_to_idx.get(char.lower(), 0) for char in abbreviation]\n",
    "    padded_abbr = pad_sequences([encoded_abbr], maxlen=max_abbr_len, padding='post')\n",
    "    \n",
    "    # Initialize decoder input with START token\n",
    "    decoder_input = np.zeros((1, max_full_len))\n",
    "    decoder_input[0, 0] = char_to_idx['<START>']\n",
    "    \n",
    "    # Generate output sequence\n",
    "    output_text = []\n",
    "    \n",
    "    for i in range(1, max_full_len):\n",
    "        # Get model prediction\n",
    "        predictions = model.predict([padded_abbr, decoder_input], verbose=0)[0]\n",
    "        sampled_token_index = np.argmax(predictions[i-1])\n",
    "        \n",
    "        # Stop if END token is predicted\n",
    "        if sampled_token_index == char_to_idx['<END>']:\n",
    "            break\n",
    "        \n",
    "        # Add predicted character to output (skip padding)\n",
    "        if sampled_token_index > 0 and sampled_token_index != char_to_idx['<PAD>']:\n",
    "            output_text.append(idx_to_char[sampled_token_index])\n",
    "        \n",
    "        # Update decoder input for next prediction\n",
    "        decoder_input[0, i] = sampled_token_index\n",
    "    \n",
    "    return ''.join(output_text)\n",
    "\n",
    "# Compare prediction methods\n",
    "for abbr in test_abbreviations:\n",
    "    try:\n",
    "        actual = df[df['Abbreviation'].str.lower() == abbr.lower()]['Full Form'].values[0]\n",
    "        \n",
    "        # Get predictions\n",
    "        greedy_result = predict_greedy(abbr, best_model, char_to_idx, idx_to_char, max_abbr_len, max_full_len)\n",
    "        beam_result = predict_with_beam_search(best_model, abbr, char_to_idx, idx_to_char, max_abbr_len, max_full_len, beam_width=3)\n",
    "        \n",
    "        # Calculate match percentages\n",
    "        def calc_match_percent(pred, actual):\n",
    "            min_len = min(len(pred), len(actual))\n",
    "            if min_len == 0:\n",
    "                return 0\n",
    "            matches = sum(p.lower() == a.lower() for p, a in zip(pred[:min_len], actual[:min_len]))\n",
    "            return (matches / max(len(pred), len(actual))) * 100\n",
    "            \n",
    "        greedy_match = \"✓\" if greedy_result.lower() == actual.lower() else \"✗\"\n",
    "        beam_match = \"✓\" if beam_result.lower() == actual.lower() else \"✗\"\n",
    "        greedy_percent = calc_match_percent(greedy_result, actual)\n",
    "        beam_percent = calc_match_percent(beam_result, actual)\n",
    "        \n",
    "        print(f\"{abbr:5} → Actual:      {actual}\")\n",
    "        print(f\"{' ':5}   Greedy:      {greedy_result}\")\n",
    "        print(f\"{' ':5}   Beam Search: {beam_result}\")\n",
    "        print(f\"{' ':5}   Greedy Match: {greedy_match} ({greedy_percent:.1f}%)\")\n",
    "        print(f\"{' ':5}   Beam Match:   {beam_match} ({beam_percent:.1f}%)\")\n",
    "        print()\n",
    "    except Exception as e:\n",
    "        print(f\"Error predicting {abbr}: {e}\")\n",
    "\n",
    "# Evaluate on the full dataset\n",
    "print(\"\\n===== Full Dataset Evaluation =====\")\n",
    "\n",
    "# Test on entire dataset\n",
    "all_results = []\n",
    "for i, row in df.iterrows():\n",
    "    abbr = row['Abbreviation']\n",
    "    actual = row['Full Form']\n",
    "    \n",
    "    try:\n",
    "        # Get predictions\n",
    "        greedy_result = predict_greedy(abbr, best_model, char_to_idx, idx_to_char, max_abbr_len, max_full_len)\n",
    "        beam_result = predict_with_beam_search(best_model, abbr, char_to_idx, idx_to_char, max_abbr_len, max_full_len, beam_width=3)\n",
    "        \n",
    "        # Calculate match percentages\n",
    "        def calc_match_percent(pred, actual):\n",
    "            min_len = min(len(pred), len(actual))\n",
    "            if min_len == 0:\n",
    "                return 0\n",
    "            matches = sum(p.lower() == a.lower() for p, a in zip(pred[:min_len], actual[:min_len]))\n",
    "            return (matches / max(len(pred), len(actual))) * 100\n",
    "            \n",
    "        exact_greedy_match = greedy_result.lower() == actual.lower()\n",
    "        exact_beam_match = beam_result.lower() == actual.lower()\n",
    "        greedy_percent = calc_match_percent(greedy_result, actual)\n",
    "        beam_percent = calc_match_percent(beam_result, actual)\n",
    "        \n",
    "        all_results.append({\n",
    "            'Abbreviation': abbr,\n",
    "            'Actual': actual,\n",
    "            'Greedy Prediction': greedy_result,\n",
    "            'Beam Prediction': beam_result,\n",
    "            'Exact Greedy Match': exact_greedy_match,\n",
    "            'Exact Beam Match': exact_beam_match,\n",
    "            'Greedy Match Percent': greedy_percent,\n",
    "            'Beam Match Percent': beam_percent,\n",
    "            'Category': row['Category'] if 'Category' in row else 'Unknown'\n",
    "        })\n",
    "    except Exception as e:\n",
    "        print(f\"Error evaluating {abbr}: {e}\")\n",
    "\n",
    "# Create results dataframe\n",
    "results_df = pd.DataFrame(all_results)\n",
    "\n",
    "# Calculate overall metrics\n",
    "print(f\"Total abbreviations evaluated: {len(results_df)}\")\n",
    "print(f\"Exact greedy match rate: {results_df['Exact Greedy Match'].mean():.4f}\")\n",
    "print(f\"Exact beam match rate: {results_df['Exact Beam Match'].mean():.4f}\")\n",
    "print(f\"Average greedy match percent: {results_df['Greedy Match Percent'].mean():.2f}%\")\n",
    "print(f\"Average beam match percent: {results_df['Beam Match Percent'].mean():.2f}%\")\n",
    "\n",
    "# Analyze by category\n",
    "if 'Category' in results_df.columns:\n",
    "    category_metrics = results_df.groupby('Category').agg({\n",
    "        'Exact Greedy Match': 'mean',\n",
    "        'Exact Beam Match': 'mean',\n",
    "        'Greedy Match Percent': 'mean',\n",
    "        'Beam Match Percent': 'mean',\n",
    "        'Abbreviation': 'count'\n",
    "    }).rename(columns={'Abbreviation': 'Count'})\n",
    "    \n",
    "    print(\"\\n----- Performance by Category -----\")\n",
    "    print(category_metrics)\n",
    "    \n",
    "    # Save detailed results\n",
    "    results_df.to_csv('prediction_results_enhanced.csv', index=False)\n",
    "    \n",
    "    print(\"\\nDetailed results saved to prediction_results_enhanced.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19680b78-6f8b-4d34-ae6b-687a448034ce",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (LSTM Env)",
   "language": "python",
   "name": "lstm_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
